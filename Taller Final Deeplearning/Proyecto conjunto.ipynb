{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28914b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo las imágenes\n",
      "Rostros:  cliente_1/img_0.png\n",
      "Rostros:  cliente_1/img_1.png\n",
      "Rostros:  cliente_1/img_10.png\n",
      "Rostros:  cliente_1/img_11.png\n",
      "Rostros:  cliente_1/img_12.png\n",
      "Rostros:  cliente_1/img_13.png\n",
      "Rostros:  cliente_1/img_14.png\n",
      "Rostros:  cliente_1/img_15.png\n",
      "Rostros:  cliente_1/img_16.png\n",
      "Rostros:  cliente_1/img_17.png\n",
      "Rostros:  cliente_1/img_18.png\n",
      "Rostros:  cliente_1/img_19.png\n",
      "Rostros:  cliente_1/img_2.png\n",
      "Rostros:  cliente_1/img_3.png\n",
      "Rostros:  cliente_1/img_4.png\n",
      "Rostros:  cliente_1/img_5.png\n",
      "Rostros:  cliente_1/img_6.png\n",
      "Rostros:  cliente_1/img_7.png\n",
      "Rostros:  cliente_1/img_8.png\n",
      "Rostros:  cliente_1/img_9.png\n",
      "Modelo almacenado...\n",
      "Entrenando el reconocedor...\n",
      "Leyendo las imágenes\n",
      "Rostros:  cliente_1/img_0.png\n",
      "Rostros:  cliente_1/img_1.png\n",
      "Rostros:  cliente_1/img_10.png\n",
      "Rostros:  cliente_1/img_11.png\n",
      "Rostros:  cliente_1/img_12.png\n",
      "Rostros:  cliente_1/img_13.png\n",
      "Rostros:  cliente_1/img_14.png\n",
      "Rostros:  cliente_1/img_15.png\n",
      "Rostros:  cliente_1/img_16.png\n",
      "Rostros:  cliente_1/img_17.png\n",
      "Rostros:  cliente_1/img_18.png\n",
      "Rostros:  cliente_1/img_19.png\n",
      "Rostros:  cliente_1/img_2.png\n",
      "Rostros:  cliente_1/img_3.png\n",
      "Rostros:  cliente_1/img_4.png\n",
      "Rostros:  cliente_1/img_5.png\n",
      "Rostros:  cliente_1/img_6.png\n",
      "Rostros:  cliente_1/img_7.png\n",
      "Rostros:  cliente_1/img_8.png\n",
      "Rostros:  cliente_1/img_9.png\n",
      "Modelo almacenado...\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Button\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image, ImageTk\n",
    "from facenet_pytorch import MTCNN\n",
    "import os\n",
    "import threading\n",
    "import csv\n",
    "\n",
    "class RegistroRostroPlacaApp:\n",
    "    def __init__(self, root, mtcnn):\n",
    "        self.root = root\n",
    "        self.root.title(\"Registro de Rostro y Placa\")\n",
    "\n",
    "        self.mtcnn = mtcnn\n",
    "        self.fotos_por_cliente = 20\n",
    "        self.cliente_num = 1\n",
    "        self.k = 0\n",
    "        self.destino = 'clientes/'\n",
    "        self.new_dim = (100, 100)\n",
    "        self.Ctexto_rostro = ''\n",
    "        self.Ctexto_placa = ''\n",
    "        self.path_cliente = ''\n",
    "        self.csv_filename = 'registros.csv'\n",
    "        self.cliente = ''\n",
    "        self.face_recognizer = None  # Se inicializará después de registrar rostros\n",
    "        self.training_complete = False  # Indica si el reconocedor ha sido entrenado\n",
    "        self.entrenar_reconocedor()\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.label = tk.Label(self.root, text=\"Presiona los botones para comenzar el registro de rostro y placa\")\n",
    "        self.label.pack(pady=10)\n",
    "\n",
    "        self.registrar_rostro_boton = Button(self.root, text=\"Registrar Rostro\", command=self.registrar_rostro)\n",
    "        self.registrar_rostro_boton.pack(pady=10)\n",
    "\n",
    "        self.registrar_placa_boton = Button(self.root, text=\"Registrar Placa\", command=self.registrar_placa)\n",
    "        self.registrar_placa_boton.pack(pady=10)\n",
    "\n",
    "        self.reconocimiento_rostro_boton = Button(self.root, text=\"Reconocimiento de Rostro\", command=self.reconocimiento_rostro)\n",
    "        self.reconocimiento_rostro_boton.pack(pady=10)\n",
    "\n",
    "    def registrar_rostro(self):\n",
    "        if not self.training_complete:\n",
    "            self.entrenar_reconocedor()  # Entrenar el reconocedor de rostros\n",
    "            self.training_complete = True  # Indicar que el entrenamiento está completo\n",
    "\n",
    "        if self.k == 0:\n",
    "            self.registrar_rostro_boton.config(state=tk.DISABLED)\n",
    "            self.cliente = f\"cliente_{self.cliente_num}\"\n",
    "            path_cliente = self.destino + self.cliente\n",
    "\n",
    "            while os.path.exists(path_cliente):\n",
    "                self.cliente_num += 1\n",
    "                self.cliente = f\"cliente_{self.cliente_num}\"\n",
    "                path_cliente = self.destino + self.cliente\n",
    "\n",
    "            print(\"Creando el directorio para: '{}' \".format(path_cliente))\n",
    "            os.makedirs(path_cliente)\n",
    "\n",
    "            self.path_cliente = path_cliente\n",
    "\n",
    "            self.thread = threading.Thread(target=self.capturar_video_rostro, args=(path_cliente,))\n",
    "            self.thread.start()\n",
    "\n",
    "    def capturar_video_rostro(self, path_cliente):\n",
    "        source = 0\n",
    "        cam = cv2.VideoCapture(source)\n",
    "\n",
    "        while self.k < self.fotos_por_cliente:\n",
    "            ret, frame = cam.read()\n",
    "\n",
    "            if not ret or frame is None:  # Verificar si la captura fue exitosa y frame no es None\n",
    "                print(\"Error al capturar el fotograma.\")\n",
    "                break\n",
    "\n",
    "            frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            boxes, confidence = self.mtcnn.detect(frame_pil)\n",
    "\n",
    "            if np.ndim(boxes) != 0:\n",
    "                box = boxes[0]\n",
    "                c = confidence[0]\n",
    "                box = box.astype(int)\n",
    "                x, y, w, h = box\n",
    "\n",
    "                if x > 0 and y > 0 and c > 0.95:\n",
    "                    cv2.rectangle(frame, (x, y), (w, h), (0, 255, 0), 2)\n",
    "                    cv2.imshow('frame', frame)\n",
    "                    print(f\"Probabilidad rostro: {c}\")\n",
    "                    f_region = frame_pil.crop(box)\n",
    "                    f_region = f_region.resize(self.new_dim)\n",
    "                    new_name = path_cliente + '/img_' + str(self.k) + '.png'\n",
    "                    self.k += 1\n",
    "                    f_region.save(new_name)\n",
    "\n",
    "            cv2.imshow('frame', frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27:\n",
    "                break\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        self.label.config(text=\"Registro de rostro completado\")\n",
    "        self.registrar_rostro_boton.config(state=tk.NORMAL)\n",
    "        self.k = 0\n",
    "\n",
    "    # Agregar información al archivo CSV\n",
    "        with open(self.csv_filename, 'a', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            row = [self.cliente] + [f'{self.path_cliente}/img_{i}.png' for i in range(1, self.fotos_por_cliente + 1)] + [self.Ctexto_rostro]\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "    def registrar_placa(self):\n",
    "        if self.k == 0:\n",
    "            self.registrar_placa_boton.config(state=tk.DISABLED)\n",
    "            self.thread = threading.Thread(target=self.capturar_video_placa)\n",
    "            self.thread.start()\n",
    "\n",
    "    def capturar_video_placa(self):\n",
    "        source = 0\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        Ctexto = ''\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if ret is False:\n",
    "                break\n",
    "\n",
    "            al, an, c = frame.shape\n",
    "\n",
    "            x1 = int(an / 3)\n",
    "            x2 = int(x1 * 2)\n",
    "\n",
    "            y1 = int(al / 3)\n",
    "            y2 = int(y1 * 2)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            recorte = frame[y1:y2, x1:x2]\n",
    "\n",
    "            mB = recorte[:, :, 0]\n",
    "            mG = recorte[:, :, 1]\n",
    "            mR = recorte[:, :, 2]\n",
    "\n",
    "            Color = cv2.absdiff(mG, mB)\n",
    "\n",
    "            _, umbral = cv2.threshold(Color, 40, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            contornos, _ = cv2.findContours(umbral, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            contornos = sorted(contornos, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "\n",
    "            for contorno in contornos:\n",
    "                area = cv2.contourArea(contorno)\n",
    "                if 500 < area < 5000:\n",
    "                    x, y, ancho, alto = cv2.boundingRect(contorno)\n",
    "                    xpi, ypi, xpf, ypf = x + x1, y + y1, x + ancho + x1, y + alto + y1\n",
    "\n",
    "                    cv2.rectangle(frame, (xpi, ypi), (xpf, ypf), (255, 255, 0), 2)\n",
    "\n",
    "                    placa = frame[ypi:ypf, xpi:xpf]\n",
    "                    alp, anp, _ = placa.shape\n",
    "\n",
    "                    Mva = np.zeros((alp, anp))\n",
    "\n",
    "                    mBp = placa[:, :, 0]\n",
    "                    mGp = placa[:, :, 1]\n",
    "                    mRp = placa[:, :, 2]\n",
    "\n",
    "                    for col in range(alp):\n",
    "                        for fil in range(anp):\n",
    "                            Max = max(mRp[col, fil], mGp[col, fil], mBp[col, fil])\n",
    "                            Mva[col, fil] = 255 - Max\n",
    "\n",
    "                    _, bin = cv2.threshold(Mva, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                    bin = bin.reshape(alp, anp)\n",
    "                    bin = Image.fromarray(bin)\n",
    "                    bin = bin.convert(\"L\")\n",
    "\n",
    "                    if 36 < alp < 82:\n",
    "                        pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "                        config = \"--psm 1\"\n",
    "                        texto = pytesseract.image_to_string(bin, config=config)\n",
    "\n",
    "                        if len(texto) >= 7:\n",
    "                            Ctexto = texto\n",
    "\n",
    "                    break\n",
    "\n",
    "            cv2.putText(frame, 'Procesando placa', (x1 - 30, y1 + 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (x1, y1 + 220), (x2, y1 + 260), (0, 0, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, Ctexto[0:7], (x1 + 40, y1 + 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow(\"Registro de Placa\", frame)\n",
    "\n",
    "            t = cv2.waitKey(1)\n",
    "            if t == ord('q') or t == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.label.config(text=\"Registro de placa completado\")\n",
    "        self.registrar_placa_boton.config(state=tk.NORMAL)\n",
    "\n",
    "        # Agregar información al archivo CSV\n",
    "        with open(self.csv_filename, 'a', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            row = [self.cliente] + [f'{self.path_cliente}/img_{i}.png' for i in range(1, self.fotos_por_cliente + 1)] + [self.Ctexto_placa]\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "    def entrenar_reconocedor(self):\n",
    "        dataPath = self.destino\n",
    "        peopleList = os.listdir(dataPath)\n",
    "        labels = []\n",
    "        facesData = []\n",
    "        label = 0\n",
    "\n",
    "        for nameDir in peopleList:\n",
    "            personPath = dataPath + '/' + nameDir\n",
    "            print('Leyendo las imágenes')\n",
    "\n",
    "            for fileName in os.listdir(personPath):\n",
    "                print('Rostros: ', nameDir + '/' + fileName)\n",
    "                labels.append(label)\n",
    "                img_path = personPath + '/' + fileName\n",
    "                facesData.append(cv2.imread(img_path, 0))  # Utilizar la imagen leída\n",
    "            label += 1\n",
    "\n",
    "        if facesData and labels:  # Verificar que haya datos antes de entrenar\n",
    "            self.face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "            self.face_recognizer.train(facesData, np.array(labels))\n",
    "            self.face_recognizer.write('modeloLBPHFace.xml')\n",
    "            print(\"Modelo almacenado...\")\n",
    "        else:\n",
    "            print(\"No se encontraron datos para entrenar el modelo.\")\n",
    "\n",
    "            \n",
    "    def reconocimiento_rostro(self):\n",
    "        if not self.training_complete:\n",
    "            print(\"Entrenando el reconocedor...\")\n",
    "            self.entrenar_reconocedor()\n",
    "            self.training_complete = True\n",
    "\n",
    "        cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "        faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            auxFrame = gray.copy()\n",
    "\n",
    "            faces = faceClassif.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                rostro = auxFrame[y:y+h, x:x+w]\n",
    "                rostro = cv2.resize(rostro, (150, 150), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                result = self.face_recognizer.predict(rostro)\n",
    "\n",
    "                cv2.putText(frame, 'Cliente {}'.format(result[0] + 1), (x, y-5), 1, 1.3, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "                if result[1] < 70:\n",
    "                    cv2.putText(frame, 'Reconocido: {}'.format(result[0] + 1), (x, y-25), 2, 1.1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(frame, 'Desconocido', (x, y-20), 2, 0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow('Reconocimiento de Rostro', frame)\n",
    "            k = cv2.waitKey(1)\n",
    "            if k == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = 'cpu'\n",
    "    mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "    root = tk.Tk()\n",
    "    app = RegistroRostroPlacaApp(root, mtcnn)\n",
    "    root.mainloop()\n",
    "\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b54c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c2324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
